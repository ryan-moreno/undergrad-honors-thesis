% Modify this file to complete your dissertation
\ProvidesPackage{preamble}

\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{ifpdf}
\usepackage{array}
\usepackage{color, colortbl}
\definecolor{Gray}{gray}{0.85}
\definecolor{LightCyan}{rgb}{0.88,1,1}

\ifpdf
  \usepackage[pdftex]{graphicx}
\else
  \usepackage[dvips]{graphicx}
\fi

\usepackage{afterpage}
\usepackage{rotating}
%\usepackage{subfigure}
% Change the CLASS FILE from WSUclass to bookbinding (and edit class file names accordingly) after your thesis is turned in electronically so you can get your dissertation bound and don't forget to change the above from oneside to twoside!!!!!!!!!!!!!!
\usepackage{fancyhdr}
  \fancyfoot[C,CO]{\textbf{\thepage}}
  \pagestyle{plain}
  \renewcommand{\chaptermark}[1]{\markboth{\chaptername \ \thechapter \ \ #1}{}}
  \renewcommand{\sectionmark}[1]{\markright{\thesection \ \ #1}}

% The caption package allows us to change the formatting of figure captions.
% The commands here change to the suggested caption format: single spaced and a bold tag
\usepackage[margin=0.3in,labelfont=bf,labelsep=none]{caption}
 \DeclareCaptionFormat{suggested}{\singlespace#1#2 #3\par\doublespace}
 \captionsetup{format=suggested}

% The cite package cleans up the way citations are handled.  For example, it
% changes the citation [1,2,3,6,7,8,9,10,11] into [1-3,6-11].  If your advisor
% wants superscript citations, use the overcite package instead of the cite package.
%\usepackage{cite}

% The makeidx package makes your index for you.  To make an index entry,
% go to the place in the book that should be referenced and type
%  \index{key}
% An index entry labeled "key" (or whatever you type) will then
% be included and point to the correct page.
\usepackage{makeidx}


\makeindex

% The url package allows for the nice typesetting of URLs.  Since URLs are often
% long with no spaces, they mess up line wrapping.  The command \url{http://www.physics.byu.edu}
% allows LaTeX to break the url across lines at appropriate places: e.g. http://www.physics.byu.edu
\usepackage{url}
\urlstyle{rm}

% The hyperref package provides automatic linking and bookmarking for the table
% of contents, index, equation references, and figure references.
%
% To include a link in your pdf use \href{URL}{Text to be displayed}.  If your
% display text is the URL, you probably should use the \url{} command discussed
% above.
%
% To add a bookmark in the pdf you can use \pdfbookmark.  You can look up its usage
% in the hyperref package documentation
\usepackage[bookmarksnumbered,pdfpagelabels=true,plainpages=false,colorlinks=true,
            linkcolor=black,citecolor=black,urlcolor=blue]{hyperref}

% floating point calculations          
\usepackage{siunitx}
\usepackage{calculator}
\usepackage{calculus}
\usepackage{longtable}

%   \makepreliminarypages : Makes the preliminary pages
%   \clearemptydoublepage : same as \cleardoublepage but doesn't put page numbers
%                           on blank intervening pages
%   \singlespace          : switch to single spaced lines
%   \doublespace          : switch to double spaced lines
\newcommand{\bibs}{DissertationRefs}
\newcommand{\comments}[1]{}

% ==================================================== %
%                                                      %
%   Fill in these fields for the preliminary pages     %
%                                                      %
% ==================================================== %

% For Senior and honors this is the year and month that you submit the thesis
% For Masters and PhD, this is your graduation date
  \Year{2020}
  \Month{May}
  \Author{Ryan Rene Moreno}
  \University{University of Southern California}
  \Department{Viterbi School of Engineering}
  \DegreeShort{Undergraduate Honors Thesis}

% If you have a long title, split it between two lines. The \TitleBottom field defines the second line
% A two line title should be an "inverted pyramid" with the top line longer than the bottom.
  \TitleTop{Data Efficiency in Named Entity Recognition}
  \TitleMiddle{}
  \TitleBottom{ }

% Your research advisor
  \Advisor{Dr. Xiang Ren}
  \AdvisorTitle{Research Advisor}

% The representative of the department who will approve your thesis (usually the chair) THIS DOESN'T MATTER FOR WSU
  \DepRep{}
  \DepRepTitle{}

% Acknowledge those who helped and supported you
  \Acknowledgments{
Thank you to Yuchen (Bill) Lin, the Ph.D. student who mentored me on both the entity trigger and data augmentation projects. Thank you for answering my questions and keeping me actively involved in the projects. I would also like to thank Dongho Lee, the masters student I worked with closely on the entity trigger project. Finally, thank you to Dr. Xiang Ren for the opportunity to work in his research lab.
}


% The text of your abstract
% Known bugs
%   Having a tiny bit of the abstract spill to second page defeats page number removal.
%   Workaround: make the abstract a little longer or a little shorter.
%
  \Abstract{
  Named entity recognition (NER) is a fundamental information extraction task that attempts to extract entities from a given text and classify them using pre-defined categories (e.g. persons, locations, or organizations) \citep{2007Survey}.
  Neural NER models are powerful in settings in which an abundance of ground-truth training data is available \citep{LampleNER}. However, human annotation is expensive and time-consuming, especially in technical domains, such as biomedical publications, in which the human annotator must be able to understand and contextualize technical jargon. Unfortunately, neural NER model performance decreases significantly when training data is restricted \citep{TriggerNER}. Thus, a crucial research question is how we can most efficiently collect and use human-annotated ground-truth data. In this thesis, I investigate two potential solutions. First, I explore a novel way of collecting human-annotated data by gathering both ground-truth entity labels and \textit{entity triggers} -- the phrases which cue entities. This approach allows for state-of-the-art results using a smaller set of human annotations. Second, I explore automated methods to create adversarial data to evaluate models and additional training data without any additional human input.

  We hypothesize that collecting human explanations of the annotators' choices in entity labels could provide a more label-efficient learning of NER models. An entity trigger is a group of words in a sentence that helps to explain why a human would recognize an entity in the sentence. After collecting human annotations for both entities and entity triggers we train a neural network to predict entity triggers in unlabeled sentences. We use these predicted entity triggers as additional supervision for the final goal of predicting entities. Our experiments demonstrate the cost effectiveness of using entity triggers. Training our framework on only 20\% of the trigger-annotated training sentences results in a comparable performance to conventional approaches using 70\% of the training data.
  
  
  An adversarial example for a neural network is an example that is created by perturbing a correctly classified example, causing the model to misclassify the  adversarial example.
Adversarial examples are useful in part because they demonstrate the limits of state-of-the-art NER models. By creating adversarial data to effectively trick a NER model, we develop a better idea of the model's brittleness, which can guide future research directions for making the model more robust. Adversarial examples are particularly important because test data is usually collected in a similar manner as the training and dev data, so models are biased towards that particular writing style~\citep{SEARs}. When used in real-world applications, using brittle models can be dangerous.

Another use of adversarial examples, the use that I focus on in this thesis, is data augmentation by adversarial training. By developing scripts to create adversarial examples, I've effectively developed scripts to take a set of labeled data and produce additional, slightly different, labeled data. I hypothesize that since the adversarial examples of our test data are able to trick our NER models, the adversarial examples must have implicit knowledge that the NER model currently lacks, knowledge which could improve the NER model if it was embedded into the training data. With this in mind, I use the same scripts for creating adversarial examples to augment the training data, creating more, slightly different, training data without additional human annotation cost. This approach --  augmenting the training data using techniques for generating adversarial test examples -- is called \textit{adversarial training}.
My experiments show that adversarial training improves the NER models' robustness to adversarial attacks while retaining its effectiveness on the original test data sets. 
}

% The text of your dedication
% This page is OPTIONAL. To remove, comment out \dedicationpage in diss.tex
  \Dedication{
    TODO
}


% ------------- These remaining fields are only necessary for masters and PhD ----------------------

% The members of your graduate committee (masters only need A and B, PhD need all 4)
  \MemberA{Jane Austin}
  \MemberATitle{Ph.D.}
  \MemberB{John F.\ Kennedy}
  \MemberBTitle{Ph.D.}

% Shortcuts
\newcommand{\figref}[1]{Figure \ref{#1}}

% fancy columns for tables [allow text to wrap and justification]
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}